{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYu/KQBoyLYapWS9lcSHJY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/llazdll/Linear_Regression/blob/main/Linear_Regression_autograd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "imports"
      ],
      "metadata": {
        "id": "R2VnTKqobZBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "import torch\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.optim import SGD"
      ],
      "metadata": {
        "id": "vj3iZC9ATOMt"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "Yn5q4a11g8Fq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "salary = pd.read_csv('https://github.com/ybifoundation/Dataset/raw/main/Salary%20Data.csv')\n",
        "\n",
        "X = salary['Experience Years'].values\n",
        "y = salary['Salary'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7)\n",
        "\n",
        "X_train = X_train.reshape(-1, 1)\n",
        "y_train = y_train.reshape(-1, 1)\n",
        "\n",
        "X_test = X_test.reshape(-1, 1)\n",
        "y_test = y_test.reshape(-1, 1)\n",
        "\n",
        "x_scaler = StandardScaler()\n",
        "X_train = x_scaler.fit_transform(X_train)\n",
        "\n",
        "y_scaler = StandardScaler()\n",
        "y_train = y_scaler.fit_transform(y_train)\n",
        "\n",
        "X_test = x_scaler.transform(X_test)\n",
        "y_test = y_scaler.transform(y_test)\n",
        "\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "train_set = TensorDataset(X_train, y_train)\n",
        "test_set = TensorDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=5, shuffle=True)\n",
        "test_loader = DataLoader(test_set, batch_size=5)"
      ],
      "metadata": {
        "id": "RDXNQUoXipBO"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "modele"
      ],
      "metadata": {
        "id": "nlUl3Rtrg6je"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Linear(1, 1)\n",
        "model"
      ],
      "metadata": {
        "id": "B-YDDlVDvUl0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7f1395e-08d4-4990-adfb-b15cb435a001"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=1, out_features=1, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "opimizer"
      ],
      "metadata": {
        "id": "q4-j0i7Rg4a5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.MSELoss()"
      ],
      "metadata": {
        "id": "w9OBjTy_i-6J"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)"
      ],
      "metadata": {
        "id": "OERaW2F1jBD-"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train"
      ],
      "metadata": {
        "id": "qD9-a_pGg2Au"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 50"
      ],
      "metadata": {
        "id": "yNvHCAvsjFYf"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(n_epochs):\n",
        "  for x_batch, y_batch in train_loader:\n",
        "\n",
        "    # model\n",
        "    y_hat = model(x_batch)\n",
        "\n",
        "    # loss\n",
        "    loss = loss_fn(y_hat, y_batch)\n",
        "\n",
        "    # gradient\n",
        "    loss.backward()\n",
        "\n",
        "    # update\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewKyDHyUjxbe",
        "outputId": "bf86e0b4-b696-4bc3-c77d-ca1ed454c256",
        "collapsed": true
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.03406643122434616\n",
            "0.04123764485120773\n",
            "0.005841558333486319\n",
            "0.05667666718363762\n",
            "0.05595890432596207\n",
            "0.05409206077456474\n",
            "0.05543609708547592\n",
            "0.05449863523244858\n",
            "0.01929217204451561\n",
            "0.039117373526096344\n",
            "0.021591898053884506\n",
            "0.06418830901384354\n",
            "0.03547392413020134\n",
            "0.06983970105648041\n",
            "0.05360926315188408\n",
            "0.041917018592357635\n",
            "0.022751828655600548\n",
            "0.009636322036385536\n",
            "0.041146647185087204\n",
            "0.07611332833766937\n",
            "0.014259313233196735\n",
            "0.04740601405501366\n",
            "0.045192889869213104\n",
            "0.008157491683959961\n",
            "0.0395110584795475\n",
            "0.05630500242114067\n",
            "0.055553972721099854\n",
            "0.00354894925840199\n",
            "0.03670486435294151\n",
            "0.05953475832939148\n",
            "0.0136457160115242\n",
            "0.04649859666824341\n",
            "0.04960174858570099\n",
            "0.04064464196562767\n",
            "0.05690900608897209\n",
            "0.03839464858174324\n",
            "0.029880374670028687\n",
            "0.06416238844394684\n",
            "0.01957036554813385\n",
            "0.04749303311109543\n",
            "0.042872171849012375\n",
            "0.04282107949256897\n",
            "0.04751940444111824\n",
            "0.05948447436094284\n",
            "0.012938407249748707\n",
            "0.053116101771593094\n",
            "0.03868043050169945\n",
            "0.03099602647125721\n",
            "0.05368032306432724\n",
            "0.04947356507182121\n",
            "0.036166928708553314\n",
            "0.029399042949080467\n",
            "0.032615501433610916\n",
            "0.044845204800367355\n",
            "0.04288039356470108\n",
            "0.024288905784487724\n",
            "0.038444556295871735\n",
            "0.040439434349536896\n",
            "0.061967313289642334\n",
            "0.03834771364927292\n",
            "0.05782393366098404\n",
            "0.0355035774409771\n",
            "0.028105249628424644\n",
            "0.03075706958770752\n",
            "0.027938783168792725\n",
            "0.07783383131027222\n",
            "0.04551238939166069\n",
            "0.018084008246660233\n",
            "0.04428767412900925\n",
            "0.05965854972600937\n",
            "0.026813626289367676\n",
            "0.05283476784825325\n",
            "0.015602484345436096\n",
            "0.015264427289366722\n",
            "0.04938191920518875\n",
            "0.024531524628400803\n",
            "0.0960996150970459\n",
            "0.051675766706466675\n",
            "0.028316756710410118\n",
            "0.05146989971399307\n",
            "0.021846828982234\n",
            "0.057742953300476074\n",
            "0.0425230897963047\n",
            "0.04638470709323883\n",
            "0.08696277439594269\n",
            "0.010678998194634914\n",
            "0.0351531058549881\n",
            "0.03389443829655647\n",
            "0.02534051239490509\n",
            "0.07324280589818954\n",
            "0.04172356054186821\n",
            "0.04646454006433487\n",
            "0.04296384006738663\n",
            "0.0293098296970129\n",
            "0.06727433204650879\n",
            "0.012180514633655548\n",
            "0.056863438338041306\n",
            "0.05082859471440315\n",
            "0.029552966356277466\n",
            "0.027540156617760658\n",
            "0.017998045310378075\n",
            "0.0748446062207222\n",
            "0.017138099297881126\n",
            "0.010562630370259285\n",
            "0.049957744777202606\n",
            "0.06482229381799698\n",
            "0.04866712540388107\n",
            "0.06521380692720413\n",
            "0.030553463846445084\n",
            "0.04623160511255264\n",
            "0.018408440053462982\n",
            "0.01334159355610609\n",
            "0.07671002298593521\n",
            "0.06772821396589279\n",
            "0.040527015924453735\n",
            "0.052515190094709396\n",
            "0.028580958023667336\n",
            "0.033778391778469086\n",
            "0.04848887771368027\n",
            "0.03957678750157356\n",
            "0.027921345084905624\n",
            "0.0765453353524208\n",
            "0.04692843183875084\n",
            "0.04048286750912666\n",
            "0.025476735085248947\n",
            "0.017906617373228073\n",
            "0.024641400203108788\n",
            "0.04628895968198776\n",
            "0.013796200044453144\n",
            "0.08860711008310318\n",
            "0.028198495507240295\n",
            "0.04562356695532799\n",
            "0.04197419434785843\n",
            "0.050211887806653976\n",
            "0.04443664476275444\n",
            "0.04221208766102791\n",
            "0.0425865538418293\n",
            "0.011670947074890137\n",
            "0.03880792856216431\n",
            "0.05601056292653084\n",
            "0.01762654259800911\n",
            "0.03979344666004181\n",
            "0.06380973011255264\n",
            "0.027345648035407066\n",
            "0.0459073968231678\n",
            "0.055253755301237106\n",
            "0.019575605168938637\n",
            "0.05845116823911667\n",
            "0.03578329086303711\n",
            "0.017819242551922798\n",
            "0.012652404606342316\n",
            "0.03913193196058273\n",
            "0.03232473134994507\n",
            "0.05476239323616028\n",
            "0.0664844885468483\n",
            "0.047451019287109375\n",
            "0.02064044401049614\n",
            "0.045129116624593735\n",
            "0.060372788459062576\n",
            "0.0632777214050293\n",
            "0.032963190227746964\n",
            "0.01912715472280979\n",
            "0.03766658902168274\n",
            "0.04102521389722824\n",
            "0.05403133109211922\n",
            "0.031832702457904816\n",
            "0.03799348324537277\n",
            "0.046873029321432114\n",
            "0.049158401787281036\n",
            "0.016273383051156998\n",
            "0.011194624938070774\n",
            "0.08659614622592926\n",
            "0.05439266562461853\n",
            "0.016903651878237724\n",
            "0.05348682403564453\n",
            "0.01989719644188881\n",
            "0.03547040745615959\n",
            "0.026953956112265587\n",
            "0.06522414833307266\n",
            "0.04971354082226753\n",
            "0.06003312021493912\n",
            "0.029761463403701782\n",
            "0.044630736112594604\n",
            "0.0617988184094429\n",
            "0.019817354157567024\n",
            "0.020652269944548607\n",
            "0.022957589477300644\n",
            "0.06293348968029022\n",
            "0.024508483707904816\n",
            "0.024398943409323692\n",
            "0.040217138826847076\n",
            "0.09255129098892212\n",
            "0.008981148712337017\n",
            "0.0546618327498436\n",
            "0.05131763964891434\n",
            "0.035863641649484634\n",
            "0.03780288249254227\n",
            "0.06596028059720993\n",
            "0.04720286652445793\n",
            "0.031911060214042664\n",
            "0.060086436569690704\n",
            "0.02440217323601246\n",
            "0.016846368089318275\n",
            "0.07831843942403793\n",
            "0.06734992563724518\n",
            "0.035094454884529114\n",
            "0.014165657572448254\n",
            "0.03827810287475586\n",
            "0.04121296852827072\n",
            "0.05355191230773926\n",
            "0.05665764957666397\n",
            "0.02606327459216118\n",
            "0.06135572865605354\n",
            "0.04356811195611954\n",
            "0.03221023827791214\n",
            "0.02475895546376705\n",
            "0.03676037862896919\n",
            "0.06595903635025024\n",
            "0.04118310660123825\n",
            "0.0404944010078907\n",
            "0.019695164635777473\n",
            "0.043870408087968826\n",
            "0.058549243956804276\n",
            "0.014591055922210217\n",
            "0.04156305640935898\n",
            "0.03561234101653099\n",
            "0.05759010463953018\n",
            "0.03920755535364151\n",
            "0.055563271045684814\n",
            "0.03494495153427124\n",
            "0.00599251314997673\n",
            "0.04216461628675461\n",
            "0.06268582493066788\n",
            "0.04000430926680565\n",
            "0.031125575304031372\n",
            "0.036348629742860794\n",
            "0.03760489076375961\n",
            "0.05991838499903679\n",
            "0.05649846792221069\n",
            "0.02084401808679104\n",
            "0.03869437798857689\n",
            "0.03236476331949234\n",
            "0.040455352514982224\n",
            "0.060687147080898285\n",
            "0.030731523409485817\n",
            "0.04659352824091911\n",
            "0.032101940363645554\n",
            "0.016886677592992783\n",
            "0.0758989229798317\n",
            "0.02897704765200615\n",
            "0.04006019979715347\n",
            "0.059420693665742874\n",
            "0.052505213767290115\n",
            "0.03962964564561844\n",
            "0.02430487424135208\n",
            "0.04158264026045799\n",
            "0.023803094401955605\n",
            "0.0799136683344841\n",
            "0.032670918852090836\n",
            "0.03972281888127327\n",
            "0.022636782377958298\n",
            "0.03341258317232132\n",
            "0.07695899903774261\n",
            "0.04243325814604759\n",
            "0.06259357184171677\n",
            "0.012249456718564034\n",
            "0.04287167638540268\n",
            "0.03298478201031685\n",
            "0.03467688709497452\n",
            "0.07305585592985153\n",
            "0.058537423610687256\n",
            "0.04514800384640694\n",
            "0.05230063945055008\n",
            "0.023682257160544395\n",
            "0.026719462126493454\n",
            "0.037306398153305054\n",
            "0.05276642367243767\n",
            "0.05937444418668747\n",
            "0.04352961853146553\n",
            "0.010876004584133625\n",
            "0.04294927045702934\n",
            "0.037524376064538956\n",
            "0.026591170579195023\n",
            "0.033982984721660614\n",
            "0.03672122582793236\n",
            "0.061612676829099655\n",
            "0.05260737985372543\n",
            "0.0289730504155159\n",
            "0.043152619153261185\n",
            "0.03306909278035164\n",
            "0.048095714300870895\n",
            "0.061820484697818756\n",
            "0.026793280616402626\n",
            "0.02470613457262516\n",
            "0.038684047758579254\n",
            "0.042010776698589325\n",
            "0.05812406539916992\n",
            "0.03153204917907715\n",
            "0.027874823659658432\n",
            "0.048332761973142624\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "vBusIpcvghUZ"
      },
      "source": [
        "### ðŸŸ§ **Test**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  for x_batch, y_batch in test_loader:\n",
        "    y_hat = model(x_batch)\n",
        "    error = nn.functional.l1_loss(y_hat, y_batch)\n",
        "    print(error)\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd9ea580-1222-4a15-9382-19e059b5a949",
        "id": "9w-POgP0ghUa"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.1565)\n",
            "tensor(0.1647)\n",
            "tensor(0.2599)\n"
          ]
        }
      ]
    }
  ]
}